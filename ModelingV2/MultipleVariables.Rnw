\begin{itemize}
\item Main effects
\item Partial derivatives
\item Prediction intervals


\end{itemize}

\marginnote{Remember to load the \pkg{mosaic} and \pkg{mosaicData} packages:
<<>>=
require(mosaic, mosaicData)
@
}


A competent trebuchet operator will tell you that the counter-weight has a big influence on the throwing distance.  The trebuchet operator has the option of adding or taking away from the counter-weight in order to set the throwing distance.  If throwing distance is a function of both projectile weight (\code{pwt}) and counter-weight (\code{cwt}), it's appropriate to include both variables as inputs.  

A simple way to do this
<<>>=
mod2 <- lm( dist ~ pwt + cwt, data=TrebTrials)
@

As always, \function{makeFun} will extract the model function in a form that can be used to calculate the output for any given inputs.
<<>>=
fun2 <- makeFun( mod2 )
@

For instance, a 50 gm projectile with a 3 kg counterweight gives\Pointer{It's better to use \code{fun2(pwt=50,cwt=3)}, which explicitly identifies which input is being assigned to which number, than \code{fun2(50, 3)}.  After all, can you be sure that you have the 50 and 3 in the right order?  With named inputs, the order doesn't matter.}
<<>>=
fun2(pwt=50, cwt=3)
@

Or, with prediction intervals at the 50\% level often used in ballistics ...\TeachingTip{Again, students can work with confidence intervals even while they are developing an understanding of their meaning.}
<<>>=
fun2(pwt=50, cwt=3, interval="prediction", level=0.5)
@

\marginnote{Once students understand that the name assigned to a function should be in the format $f$ rather than $f(x)$, you may want to start assigning more descriptive names to functions.  Notice that in writing about functions, we use the typographical notation \function{f} rather than the bare 
name \bariable{f}.  But remember than in assigning a name to a function not to use the parentheses after the function name.}

There are two input variables here, so an appropriate graphical display is a contour plot
<<fig.height=4,fig.width=4,tidy=FALSE>>=
plotFun( fun2(pwt=P, cwt=C) ~ P & C, 
        P.lim=range(10,70),C.lim=range(.5,3),
        xlab="Projectile (gms)",
        ylab="Counter Weight (kg)",
        main="Distance Thrown (cm)")
@
A trebuchet operator could use this graph as a guide to setting projectile and counterweights to reach a specified distance.  For instance, given a 30 gm projectile and a target at distance 800 cm,  what counter-weight is needed?  \DiggingDeeper{The variables \code{P} and \code{C} are placeholders.  You could replace them with any valid names.  On the other hand, \code{pwt} and \code{cwt} are the names needed to make sure that the input values are assigned to the right place in the calculation.}

Another helpful way to examine and interpret the model is to look at the effect of changing one variable while holding the other constant.  For instance, for a 30 gm projectile and a 2 kg counter-weight, adding 100 gms to the counterweight changes the distance by this amount:
<<>>=
fun2(cwt=2.1, pwt=30) - fun2(cwt=2, pwt=30)
@
The throw-distance increase per unit increase of the counter-weight is a helpful number for a trebuchet technician to know.  If the previous shot was 60 cm too short, adding 150 gm to the counter-weight looks the right thing to do.

Or, suppose that it is very difficult to change the counter-weight in the field, but a small amount of weight can be added or taken away from the projectile.  The corresponding calculation holds \code{cwt} constant and changes \code{pwt}.
<<>>
fun2(cwt=2, pwt=35) - fun2(cwt=2, pwt=30)
@
Adding 5 gms to the projectile reduces the throw distance by about 43 cm.  So, to compensate for a shot that is 60 cm too short, take away about 7.5 gm from the projectile.



\subsection{Comparing two models}

We've now built two models of the trebuchet throw distance: \code{mod1} (from the previous chapter) and \code{mod2}.  To remind you ...
<<>>=
mod1 <- lm(dist ~ pwt, data=TrebTrials)
mod2 <- lm(dist ~ pwt + cwt, data=TrebTrials)
@
Which one is better?

By and large, students will reach into their high-school math experience and translate the question into, ``Which model is right?" Make sure to explain to them that neither model could possibly be ``right."  Each of the models undoubtedly leaves out details that will affect the throw distance: the wind strength, the amount of lubrication on the pivot, swelling of the wood due to changes in humidity.

The point of a model is not to be ``right," but to be useful.  And utility depends on the purpose for which the model will be used.  If you want to adjust the counter-weight to reach a target, \code{mod2} is better simply because it include the counter-weight as an input.  But if the purpose is to adjust the projectile weight, either model could be used.

Another way to think about ``better" is in terms of the quality of the prediction.  A prediction that has a narrower prediction interval will be more useful than a prediction with a wide prediction interval.  For these two models, at the nominal trebuchet setting of counter-weight at 2 kg and projectile at 50 gm, the prediction intervals are:\Pointer{Strictly speaking, there's no need to repeat the \function{makeFun} statements.  \code{fun1} and \code{fun2} have already been made and are still in computer memory.  The repetition is for the human reader, who might otherwise forget the step of extracting the function from the model with \code{makeFun}.}
<<>>=
fun1 <- makeFun(mod1)
fun1(pwt=50, interval="prediction", level=0.5)
fun2 <- makeFun(mod2)
fun2(pwt=50, cwt=2, interval="prediction", level=0.5)
@

The interval for \code{mod2} is $612-484 = 128$ cm.  For \code{mod1}, the interval is $755-334 = 421$ cm.  To judge from this, \code{mod2} is better.

\section{Residuals}

The differences between the actual values of the response variable and the predicted values are called the residuals.  Each case has its own residual: a number that may be positive or negative, depending on whether the actual value  is greater or less than the predicted values.  Here's a calculation of the residuals: subtract the predicted values from the actual values.\Pointer{In evaluating the model function, the inputs take on a redundant-looking form:
\code{fun2(pwt=pwt, cwt=cwt)}.  You might wonder what is the point of \code{pwt=pwt} rather than simply \code{pwt}.  Recall that the inputs to functions have names.  Having been created from \code{mod2}, the function \code{fun2} names its inputs based on the response variables used in the model.  Those names appear on the left-hand side of the \code{=}.  On the right-hand side goes the values you want to use as inputs. In the \function{transform} statement you write \code{pwt=pwt} to say, "Use as the \code{pwt} input the values of the \code{pwt} variable from \code{TrebTrials}.}
<<>>=
mod2 <- lm(dist ~ pwt + cwt, data=TrebTrials)
fun2 <- makeFun(mod2)
TrebTrials <- transform( TrebTrials, 
                         resids=dist - fun2(pwt=pwt, cwt=cwt) )
@

The residuals are so important that R provides a function for calculating them: \code{resid(mod2)}.  Similarly the predicted, or ``fitted," values can be calculated with \code{fitted(mod2)}.

Each case has its own residual.  You can look at the distribution of residuals in the usual way: 
<<>>=
densityplot( ~ resids, data=TrebTrials)
@
This distribution is always centered on zero:
<<>>=
mean( ~ resids, data=TrebTrials)
@
This is a result of the fitting process, which aims to make the residuals as small as possible.

Rather than the location of the center, a meaningful description of the size of the residuals is the standard deviation or, equivalently, the variance.\Pointer{The standard deviation is the square root of the variance: they contain the same information.}
<<>>=
var( ~ resids, data=TrebTrials)
sd(  ~ resids, data=TrebTrials)
@

\section{R-squared}

The coefficient of determination, written R$^2$, is a simple and very widely used summary of how close a model fits the data.  R$^2$ measures how much of the variation in the response variable is accounted for by the explanatory variables.

Calculating R$^2$ from a model is easy:
<<>>=
rsquared(mod1)
rsquared(mod2)
@

The basic interpretation of R$^2$ is also straightforward. R$^2$ is a number between zero and one.  Values of R$^2$ near zero indicate that the model doesn't account for much of the response variable.  Values near one indicate that the model account for almost all of the variation in the response.

Just knowing these properties of R$^2$ are almost enough to let students work productively with it.  You may, of course want to say and perhaps justify some background beyond the usual formula.
\begin{itemize}
\item The conventional measure of case-to-case variation in a variable is called the variance.  It's the square of the standard deviation.\Pointer{Many people think of the variance as a way-point in calculating a standard deviation.  Actually, the variance is important in its own right.}
\item R$^2$ is the ratio of the ``size" of the fitted model values to the size of the actual values of the response variable. "Size" is measured with the variance. That is:
<<>>=
var(fitted(mod1)) / var(dist)
var(fitted(mod2)) / var(dist)
@
\end{itemize}

When building models, you can use R$^2$ to judge whether to add more detail to a model.  For instance, consider the model that takes as explanatory variables the trebuchet configuration as well as the projectile and counter-weight.
<<>>=
mod3 <- lm(dist ~ pwt + cwt + config, data=TrebTrials)
rsquared(mod3)
@

Evidently, \code{config} accounts for a bit of \code{dist} beyond what \code{pwt} and \code{cwt} have to offer.

\section{Model terms and interactions}

In a formula like \code{dist \tilde\ pwt + cwt + config} each of the explanatory variables can be called a {\em model term}.  There would be little point in using this additional terminology if a model term were exactly the same as an explanatory variable.  But models can have terms that are not variables.

The relationship \code{dist \tilde\ pwt + cwt + config} actually contains a model term other that \code{pwt}, \code{cwt}, and \code{config}.  That additional term is the "variable" \code{1}.  This term is often called the {\em intercept term}.

You could, in fact, include \code{1} explicitly in the formula: \code{dist ~ 1 + pwt + cwt + config}.  This won't change anything about the model simply because \function{lm} will, by default, add the intercept term to every model.\DiggingDeeper{You can tell \function{lm} not to exclude the intercept with a formula involving \code{-1}, for instance, \code{dist ~ pwt + cwt + config - 1}.  You will rarely want to build a model without an intercept term.}

Another important kind of model term is called an {\em interaction term}.  An interaction is used when the effect of one variable, say \code{pwt}, is changed (or modulated or altered) by another variable.  In the formula notation, an interaction term is added with an expression like \code{pwt:cwt}.\Pointer{Students will often form a misconception that an interaction term like \code{pwt:cwt} indicates that one of the variables is influencing the other variable, as if the weight of the projectile influences the counterweight.  Instead, interaction terms show how two (or more) explanatory variables ``work together" to form the output.  With the trebuchet, a term \code{pwt:cwt} means that the counter-weight has a different effect depending on the size of the projectile weight, not that the counter-weight influences the projectile weight.}

Once you start adding interaction terms to a model, you will find it convenient to have a way to refer to non-interaction terms, that is, terms that involve only one variable.  The word used for single-variable terms is ``main effect."\Pointer{The implication of using the word ``main," that single-variable terms are more important is not warranted. ``Main" terms are simply those that involve a single variable.  They might be important or unimportant compared to an interaction term.}  So you might refer to the \code{pwt} term as the main effect of projectile weight, while \code{pwt:cwt} is an interaction.

Here's a trebuchet model with an interaction term:
<<>>=
mod4 <- lm(dist ~ pwt + cwt + pwt:cwt, data=TrebTrials)
@

The R$^2$ with the interaction term is hardly bigger than without it.
<<>>=
rsquared(mod2)
rsquared(mod4)
@
This suggests that the data suggest there is little or no interaction between \code{pwt} and \code{cwt}.  In contrast, Example \ref{example:swimming} shows a situation where the interaction term is very important.


To see how the interaction term changes the model function, you can graph it.
<<>>=
fun4 <- makeFun(mod4)
plotFun(fun4(pwt=x,cwt=y) ~ x & y, 
        x.lim=range(20,60), y.lim=range(1,3),
        xlab="Projectile Weight (gm)",
        ylab="Counter-weight (kg)")
@

\section{Degrees of freedom \& nested models}

At this point, you should be able to distinguish between a variable and a model term.\Pointer{Hint: Sometimes model terms are simply variables, but some model terms are not. For instance, the intercept is a model term but involves no variable.  Interaction terms involve two or more variables.}

Another useful concept is {\em degrees of freedom} of a model.  This is more-or-less a count of the number of terms, and is a measure of how complicated the model is.  So \code{~ pwt + cwt} has two degrees of freedom, but \code{~ pwt + cwt + pwt:cwt} has three degrees of freedom.\TeachingTip{You can describe a degree of freedom as the ``amount of information" being used in the model function to generate the output.}

When categorical variables are used in a model, they can add more than one degree of freedom.  For example, \code{config} has four levels: ``a", ``b", ``B", and ``c".  Adding \code{config} to the model would therefore add three degrees of freedom.  Why should four levels correspond to three degrees of freedom?  Because once you know that the level for \code{config} a given case is not b or B or c, there is no new information to be added by saying that it must be ``a".

\section{Reprise}

At this point you have seen some ways of measuring aspects of variables and models.

\begin{itemize}
\item Measuring variation from case to case in a variable --- the variance
\item Measuring how well a model fits the data --- R$^2$
\item Measuring the complexity of a model
\end{item}

We'll use these measures when comparing two or more models to one another.

\section{ACTIVITIES}

\begin{itemize}
\item Count the degrees of freedom in a model.
\item Nesting and R$^2$ being larger in the bigger of two nested models.
\end{itemize}

\section{Example: Interaction in action}

World records in athletics get better and better over the years; a new record must be better than the previous one.  For instance, consider swimming records in the 100-meter freestyle event as they have changed over the years.  

\begin{widestuff}
<<swim-data,fig.width=6>>=
xyplot(time ~ year | sex, data=SwimRecords)
@
\end{widestuff}

The record \variable{time} depends on both \variable{sex} and \variable{year}, but it's your choice what explanatory variables to include in a model.  Here are three plausible models:
<<>>=
swim1 = lm(time~sex, data=SwimRecords)
swim2 = lm(time~year, data=SwimRecords)
swim3 = lm(time~year + sex, data=SwimRecords)
@
To plot out the model function, first extract the function from the model:
<<>>=
s1 = makeFun(swim1)
s2 = makeFun(swim2)
s3 = makeFun(swim3)
@

The first model doesn't include \variable{year}.  Still, to graph the model function on the axes, you need to include \variable{year} in the plotting statement. 

\begin{widestuff}
<<fig.width=6, fig.keep="last">>=
<<swim-data>>
plotFun(s1(sex="F")~year,add=TRUE)
plotFun(s1(sex="M")~year,add=TRUE,lty="dotdash")
@
\end{widestuff}

The function \function{s1} doesn't depend on \variable{year}, so the graphs of the function are flat with respect to \variable{year}.  The function does have \variable{sex} as an input and you can see in the graph how the function values for females (thick line) differ from those for males (thin line).

Now consider \function{s2}, which depends on \function{year} but not \function{sex}.

\begin{widestuff}
<<fig.width=6, fig.keep="last">>=
<<swim-data>>
plotFun(s2(year)~year,add=TRUE)
plotFun(s2(year)~year,add=TRUE,lty="dotdash")
@
\end{widestuff}

The functions are the same for males and females, of course, so they overlie one another on the graph.

Including both \variable{sex} and \variable{year} in the model produces a function that depends on both variables:

\begin{widestuff}
<<fig.width=6, fig.keep="last">>=
<<swim-data>>
plotFun(s3(year=year,sex="F")~year,add=TRUE)
plotFun(s3(year=year,sex="M")~year,add=TRUE,lty="dotdash")
@
\end{widestuff}

You might be surprised to see that the graph of the function for males is parallel to that for females.  That's because there was nothing in the model design that produces a different slope with respect to \variable{year} for females and males: the two lines must therefore be parallel. 

Including such a difference in a model is a matter of including an \term{interaction term} between \variable{sex} and \variable{year}:

\begin{widestuff}
<<fig.width=6, fig.keep="last">>=
swim4 = lm(time~year+sex+year:sex,data=SwimRecords)
s4 = makeFun(swim4)
<<swim-data>>
plotFun(s4(year=year,sex="F")~year,add=TRUE)
plotFun(s4(year=year,sex="M")~year,add=TRUE,lty="dotdash")
@
\end{widestuff}

\newthought{Interactions are confusing}; they imply a ``difference of differences.'' \marginnote{For students who have been exposed to the algebra of functions of two variables, it may be helpful to point out that the model $x + y + x:y$ corresponds to the polynomial $f(x,y) = a_0 + a_1 x + a_2 y + a_3 x y$.  The coefficient on the interaction term is $a_0$.  This corresponds to the mixed partial derivative, $\partial^2 f/\partial x \partial y$.  This is the calculus equivalent of ``difference of differences.''} Students tend to want to interpret the word ``interaction'' as meaning that one variable affects the other.  This is not quite right.  An interaction describes how the effect of one variable on the response is modulated by the other variable.  For example, the interaction between \variable{sex} and \variable{year} tells how the relationship between \variable{year} and world-record \variable{time} differs for the two sexes.  You see that interaction in the graph as different slopes for the fitted lines for the two sexes.

Another way to describe the interaction is that the relationship between \variable{sex} and world-record \variable{time} is changing over the years.  You can see that from the changing vertical distance between the lines for females and males. Both these ways of describing the interaction --- how the relationship between \variable{sex} and \variable{time} is modulated over the years, and how the relationship between \variable{year} and \variable{time} is different for the two sexes --- are equivalent.  Given that the slopes of the two lines is different, the vertical distance between the two lines is going to change.



\section{THIS IS FROM THE OLD VERSION}






\newpage

\section{Example: The Genetic Component of Human Height}

The world-record swim-time data is ordered enough that it's easy to draw a satisfactory functional approximation by hand.  That makes it easier for students to visualize how different model terms set the ``shape'' of the function.  But students may wonder what statistics has to do with it.

\newthought{To place things more firmly in a statistical context},\marginnote{Francis Galton, ``Correlations and their measurement, chiefly from anthropometric data'' (1889) {\em Nature} 39:238, and ``Regression towards mediocrity in hereditary stature'' (1886) {\em Journal of the Anthropological Institute of Great Britain and Ireland} 15:246-263.  For a commentary and access to further background on the data, see James Hanley, `` `Transmutting' Women into men: Galton's family data on human stature'' (2004) {\em American Statistician} 58(3):237-243)} consider the data collected by Francis Galton in 19th century London.  Galton was interested in exploring the heritability of biological traits, in particular the relationship between the heights of parents and their full-grown, adult children.  These data played an important part in the development of the correlation coefficient and regression toward the mean  

A man of his era, Galton focused on the heights of sons.  Here are both sexes of children, plotted out against the mother's height:

\begin{widestuff}
<<galton-data,fig.width=6>>=
xyplot(height ~ mother | sex, data=Galton)
@
\end{widestuff}

From the graph alone, it's obvious that height differ from males to females and there is a slight tendency that a taller mother is associated with taller children.  Here's a model that includes an interaction term between the child's sex and the mother's height:

\begin{widestuff}
<<fig.width=6, fig.keep="last">>=
<<galton-data>>
hmod1 = lm(height~mother*sex,data=Galton)
h1 = makeFun(hmod1)
plotFun(h1(mother=m,sex="F")~m,add=TRUE)
plotFun(h1(mother=m,sex="M")~m,add=TRUE,lty="dotdash")
@
\end{widestuff}

What's new in this example is that a specific line can be judged as the best fit to a cloud of data.  Certainly a student could do this by hand, but they would likely have little confidence that their particular line was best.  Certainly, the precision with which one might draw a line by hand wouldn't justify drawing lines of different slopes for the males and females.  Indeed, it remains to be seen whether the interaction term is contributing much to the model.  That sort of question provides a segue to statistical inference.  (See below.)

What's the father's role in this.  In a scatter plot, it's impossible to use both the father and the mother along on the $x$-axis, one has to choose.  There are some tricks, for example creating panels for different intervals of the father's height, but it's hard to gain much quantitative insight from the graphic.

\begin{widestuff}
<<galton-father,fig.width=5,fig.height=5,tidy=FALSE>>=
xyplot(height ~ mother | cut(father,breaks=2) + sex, data=Galton)
@
\end{widestuff}

Instead, consider a model that uses both mother's and father's height (and the child's sex) to account for the child's height.  For now, leave off the interaction terms; you can return to those later with some statistical inference tools in hand: 

\begin{widestuff}
<<fig.width=5,fig.height=5,tidy=FALSE, fig.keep="last">>=
hmod2 = lm(height~mother+father+sex,data=Galton)
h2 = makeFun(hmod2)
<<galton-father>>
plotFun(h1(mother=m,sex="F")~m,add=TRUE)
plotFun(h2(mother=m,father=64,sex="F")~m,add=TRUE,lty="dotdash")
plotFun(h2(mother=m,father=74,sex="F")~m,add=TRUE,lty="dotted")
@
\end{widestuff}

The dotted and dot-dashed lines show the mother+father model values for two different heights of father (just for female children).  For comparison, the solid line shows the model with just the mother. That the lines are different for the two different heights of father shows the association between father's height and child's height, for each given mother's height.  


\section{Partial Change}


\subsubsection{Using models for adjustment}

Occasionally, it makes sense to consider the change while varying two or more variables simultaneously.  As an example with a simple mechanism, consider trying to predict a person's wage based on their education and job experience.  The \dataframe{CPS85} data contains information from the Current Population Survey that can be used for this purpose.  First, build a model with both education and experience as explanatory variables (and whatever covariates you think appropriate), e.g.,
<<>>=
wmod = lm(wage~educ+exper,data=CPS85)
@
Wage here is in dollars per hour (in 1985).  To look at the ``effect'' of a college education, you might examine the partial difference with education varying to 16 years from 12 years while experience is being held constant at, say, 10 years. (Twelve years of education corresponds to a high-school graduate.)
<<>>=
w1 = makeFun(wmod)
w1(educ=16,exper=10)-w1(educ=12,exper=10)
@
Judging from this, the four years of extra education is associated with a predicted increase in wage of \$3.70 per hour.  

But hold on.  The four years of extra education comes by decreasing work experience by those four years (if experience is ), so the proper comparison is not a partial change in one variable alone, but a simultaneous, compensatory change in education and experience:
<<>>=
w1(educ=16,exper=10)-w1(educ=12,exper=14)
@

% EXERCISES: From the total versus partial sheets.


\newthought{You might want to try adding more detail} to the model.  There are two basic directions you might go:
\begin{itemize}
\item Use a more complicated model form such as a polynomial of weight.

For instance, here's a cubic polynomial fit to the data:
<<>>=
mod3 <- lm(dist ~ poly(pwt, 3), data=TrebTrials)
fun3 <- makeFun(mod3)
plotFun(fun3(pwt) ~ pwt, pwt.lim=c(20,60))
@
\item Use additional variables, such as the counterweight, configuration, etc.
\end{itemize}

Mathematically oriented people are often tempted to try the complicated model.  Experience tells, however, that adding more variables is, as a rule, a much more productive way to go.  The next chapter shows how to do this.


\section{Activities}

\newthought{How do we know that the prediction intervals} generated by evaluating the model function are right?\TeachingTip{This exercise helps to develop {\em mastery} of statistics.  The word ``mastery" is used in a particular sense.  Someone starting in a field generally relies on the authority of those who have expertise.  That's what is happening when students first see a statement like \code{fun1(pwd=50,interval='confidence')}. Mastery starts when students develop ways to evaluate the statements of authorities on terms that make sense to them.}%
One way to do this is to make lots of predictions and then go into the lab or the field to perform the actual event.  Comparing the actual results to the predicted results establishes how good the predictions are.

As an alternative to lab or field work, you can check the quality of predictions using the data you already have.  Here's how:

\begin{itemize}
\item Use \code{transform()} to add a new variable consisting of random numbers.  
<<>>=
CPS85 <- mutate(CPS85, rand=runif(nrow(CPS85)))
@
\item Create a subset of the cases in the data for the purposes of building the model.  Filter to collect the cases with \code{rand} below a selected variable.  0.5 is a good choice and will give approximately 50\% of the cases. 0.25 would give approximately 25\% of the cases.
<<>>=
ForFitting <- filter(CPS85, rand < 0.5)
@
\item Take the remaining cases for testing the predictions
<<>>=
ForTesting <- filter(CPS85, rand > 0.5)
@

\item Fit your model to the cases selected for this purpose and extract the model function.
<<>>=
myModel <- lm(wage ~ age + sex, data=ForFitting)
myFun   <- makeFun(myModel)
@

\item Evaluate the fitted model for the inputs in the test data
<<>>=
preds <- with(ForTesting, myFun( age=age, sex=sex))
@

\item Compare the predictions to the actual values. That is, find out how far off each prediction is compared to the actual, observed value. Note that the response variable is being compared to the predictions.  In this example, the response variable is \code{wage}.
<<>>=
Compare <- transform( ForTesting, offBy=wage - preds)
@
\item Display how big the \code{offBy}s are.  There are several ways to do this:
<<>>=
sd(offBy, data=Compare)
densityplot( ~ offBy, data=Compare)
@

\item You can even see how often the actual value is inside the prediction interval.\TeachingTip{Best to do this with a level lower than 95\% so that students can see a substantial number of cases where the prediction interval doesn't contain the actual value.}%
This is a somewhat complicated process, so don't expect your students to come up with it on their own.  Give them a working example command and let them modify it for their own data.
<<>>=
Predictions <- ForTesting %>%
  with( ., myFun(age=age, sex=sex,interval="prediction", level=0.50)) %>%
  data.frame
Predictions <- cbind(Predictions, ForTesting) 
Predictions <- transform(Predictions, 
                         isInside=lwr<wage & wage<upr)
@

Finally, see how many of the actual values fall within the prediction interval.  The proportion should match the \code{level}.
<<>>=
tally( ~ isInside, data=Predictions, format="proportion")
@

\end{itemize}

