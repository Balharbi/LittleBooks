<<echo=FALSE,include=FALSE>>=
source('../include/setup.R')
opts_chunk$set( fig.path="figures/RForStudents-" ) 
if (!exists("..makingMaster..")) {
	set_parent('Master-Starting.Rnw')
}
set.seed(123)
@




\chapter[What Students Need to Know about R]{What Students Need to Know About R\\ 
\& How to Teach It}
\label{chap:RForStudents}


\section{Using R as a Calculator}
Most students are familiar and comfortable with their hand-held calculators, so it
is natural to begin an introduction to \R\ by showing them how \R\ can be used
to perform typical calculator operations.

Try typing the following commands in the console panel.
<<rs-arithmetic>>=
5 + 3
15.3 * 23.4
sqrt(16)  # square root function
@
This last example demonstrates how functions are called within \R\ as
well as the use of comments.
Comments are prefaced with the \verb!#! character.
Comments can be very helpful when writing scripts 
with multiple commands or to annotate example code for your students.

You can save values to named variables for later reuse.

<<rs-variables1a,tidy=FALSE>>=
product = 15.3 * 23.4       # save result
product                     # display the result
product <- 15.3 * 23.4      # <- can be used instead of =
product                     
@
\TeachingTip[-16ex]{It's probably best to settle on using 
one or the other of the right-to-left assignment operators rather than to switch
back and forth.  The authors have different preferences:
two of us find the equal sign to be simpler for students and more 
intuitive, while the other prefers the arrow operator because it
represents visually what is happening in an assignment, because it
can also be used in a left to right manner, and because it makes 
a clear distinction between the assignment operator, the use of \code{=}
to provide values to arguments of functions, and the use of \code{==} to test
for equality.}%
Once variables are defined, they can be referenced in other operations
and functions.

<<rs-variables2,tidy=FALSE>>=
0.5 * product               # half of the product
log(product)                # (natural) log of the product
log10(product)              # base 10 log of the product
log(product, base=2)        # base 2 log of the product
@
\authNote{can we come up with a better (e.g. less mathematical) example?}


The semi-colon can be used to place multiple commands on one line.  
One frequent use of this is to save and print a value all in one go:

<<rs-variables-semi,tidy=FALSE>>=
15.3 * 23.4 -> product; product    # save result and show it
@


\section{Four Things to Know About \R}

As is true for most computer languages, \R\ has to be used on its terms.  
\R\ does not learn the personality and style 
of its users.  Getting along with \R\ is much easier if you keep in mind (and remind 
your students about) a few key features of the \R\ language.

\begin{enumerate}
\item \R\ is case-sensitive
\TeachingTip{Some students will be slow
to catch on to the importance of capitalization. So you may
have to remind them several times early on.} 

If you mis-capitalize something in \R\ it won't do what you want.
Unfortunately, there is not a consistent convention about how capitalization 
should be used, so you just have to pay attention when encountering new
functions and data sets.  

\item 
Functions in \R\ use the following syntax:
<<label="rs-function-syntax",eval=FALSE>>=
functionname( argument1, argument2, ... )
@
\vspace{-5mm}
\TeachingTip{Introduce functions by emphasizing the questions
\emph{What do we want the computer to do?} and 
\emph{What information does the computer need to compute this?}
The answer to the first question determines the function to use.
The answer to the second question determines what the
arguments must be.
}%
\begin{itemize}
\item The arguments are \underline{always} \emph{surrounded by (round) parentheses} and 
\emph{separated by commas}.

Some functions (like \function{data()}) 
have no required arguments, but you still need the parentheses.

\item
If you type a function name without the parentheses, you will see the \emph{code} for that
function (this generally isn't what you want unless you are curious about how 
something is implemented).
\end{itemize}
\item
TAB completion and arrows can improve typing speed and accuracy.

If you begin a command and hit the TAB key, \R\ and \RStudio\ will show you a
list of possible ways to complete the command.  If you hit TAB after the
opening parenthesis of a function, \RStudio\ will display the list of arguments
it expects.  

The up and down arrows can be used to retrieve past commands when working in the console.
\item
If you see a \code{+} prompt, it means \R\ is waiting for more input.

\Caution{Your students will sometimes find themselves in a syntactic hole from which they cannot
dig out.  Teach them about the ESC key early.}%
Often this means that you have forgotten a closing parenthesis or made some other
syntax error.  If you have messed up and just want to get back to the normal prompt,
press the escape key and start the command fresh.
\end{enumerate}

\section{Installing and Using Packages}
\label{sec:installingPackages}

\TeachingTip{If you set up an \RStudio\ server, you can install all
of the packages you want to use.  You can even configure the server to 
autoload packages you use frequently.  Students who use \R\ on their 
desktop machines will need to know how to install and load these packages, 
however.}

\R\ is open source software.  Its development is supported by
a team of core developers and a large community of users.  
One way that users support
\R\ is by providing \term{packages} that contain data and functions
for a wide variety of tasks.  
As an instructor,
you will want to select a few packages that support the way you want
to teach your course.

%\subsection{Installing packages from \cran}
If you need to install a package, most likely it will be on \cran, 
the Comprehensive R Archive Network.
Before a package can be used, it must be \term{installed} 
(once per computer or account)
and
\term{loaded} (once per \R\ session).  
Installing downloads the package software and prepares it for use
by compiling (if necessary) and putting its components in the proper
location for future use.
Loading makes a previously installed package available for use 
in an \R\ session.

\Rindex{install.packages()}%
\Rindex{require()}%

For example, to use the \pkg{mosaic} package, we must first install it:
<<eval=FALSE,tidy=FALSE>>=
install.packages("mosaic") # fetch package from CRAN 
@
and then load it:
<<>>=
require(mosaic)            # load the package before use.
@
\Caution{Remember that in RMarkdown and Rnw files, any
packages you use must be loaded within the file.}
\noindent
The \tab{Packages} tab in \RStudio\ makes installing and loading packages
particularly easy and avoids the need for \function{install.packages()}
for packages on CRAN, and makes loading packages into the console as easy
as selecting a check box.  The \function{require()} function is still
needed to load packages within RMarkdown, \pkg{knitr}/\LaTeX, and script 
files.

If you are running on a machine where you don't have privileges to
write to the default library location, you can install a personal 
copy of a package.  If the location of your personal library is 
first in \code{R_LIBS}, this will probably happen automatically.  If not,
you can specify the location manually:

<<eval=FALSE>>=
install.packages("mosaic", lib="~/R/library")
@
%On a networked machine, be sure to use a different local directory for 
%each platform since packages must match the platform.

%Binary packages have been precompiled for a 
%particular platform and are generally faster and easier to set up, if they 
%are available.  Source packages need to be compiled and built on your local
%machine.  Usually this happens automatically -- provided you have all the 
%necessary tools installed on your machine -- so the only disadvantage is the
%extra time it takes to do the compiling and building.

%\subsection{Installing other packages}

Occasionally you might find a package of interest that is not available via
a repository like \cran.  
Typically, if you find such a package, you will also find instructions
on how to install it.  If not, you can usually install directly from the 
zipped up package file.

<<eval=FALSE,echo=TRUE>>=
# repos = NULL indicates to use a file, not a repository
install.packages('some-package.tar.gz', repos=NULL)           
@


\begin{boxedText}
	From this point on, we will assume that the \pkg{mosaic}
	package has been installed and loaded.
\end{boxedText}


\section{Getting Help}

If something doesn't go quite right, or if you can't remember something, it's good to know
where to turn for help.  In addition to asking your friends and neighbors, you can use
the \R\ help system.

\subsection{?}

To get help on a specific function or data set, simply precede its name with a \code{?}:

\authNote{This isn't working properly}
<<rs-help1,eval=FALSE,tidy=FALSE>>=
?log      # help for the log function
@
<<rs-help2,eval=FALSE,tidy=FALSE>>=
?HELPrct  # help on a data set in the mosaic package
@
This will give you the documentation for the object you are interested in.

\subsection{\texttt{apropos()}}
If you don't know the exact name of a function, you can give part of the name and 
\R\ will find all functions that match.  Quotation marks are mandatory here.

<<rs-apropos>>=
apropos('tally')            # must include quotes.  single or double.
@

\subsection{\texttt{??} and \texttt{help.search()}}
If that fails, you can do a broader search using \code{??} or \function{help.search()}, 
which will find matches not only in the names of functions and data sets, 
but also in the documentation for them.  Quotation marks are optional here.


\subsection{Examples and Demos}

Many functions and data sets in \R\ include example code demonstrating typical uses.
For example,
\marginnote{Not all package authors are equally skilled at creating examples.  
Some of the examples are nonexistent or next to useless, others are excellent.}%
<<rs-example-histogram,eval=FALSE,results="hide">>=
example(xhistogram)
@
will generate a number of example plots (and provide you with the commands used to create them).
Examples such as this are intended to help you learn how specific \R\ functions work.
These examples also appear at the end of the documentation for functions and data sets.

The \pkg{mosaic} package (and some other packages as well) also includes demos.  
Demos are bits of \R\ code that can be executed using the \function{demo()} command
with the name of the demo.
To see how demos work, give this a try:
<<rs-demo,eval=FALSE,results="hide">>=
demo(lattice)
@
Demos are intended to illustrate a concept, a method, or some such thing, and are 
independent of any particular function or data set.

You can get a list of available demos using
<<rs-demo-list,eval=FALSE,results="hide">>=
demo()                     # all demos
demo(package='mosaic')     # just demos from mosaic package
@


\section{Data}
\label{sec:studentdata}%
%To be able to undertake analyses, you will need to
%load data sets into \R\ and \RStudio\ for analysis.

\subsection{Data in Packages}
Data sets in \R\ packages are the easiest to deal with.
\TeachingTip{Start out using data in packages and show students
how to import their own data once they understand how to work with
data.}%
In section \ref{sec:usingdata},
we'll describe how to load your own data into \R\ and \RStudio,
but we recommend starting with data in packages, 
and that is what we will do here, too.  Once students know 
how to work with data and what data in \R\ are supposed to look
like, they will be better prepared to import their own data sets.

Many packages contain data sets.  
You can see a list of all data sets in all loaded packages
using 

<<rs-data-list,eval=FALSE,results="hide">>=
data()
@
You can optionally choose to restrict the list to a single package:
<<rs-data-package-list,eval=FALSE,results="hide">>=
data(package="mosaic")
@

Typically (provided the author of the package allowed for lazy loading of data) 
you can use data sets by simply typing their names.  But if you have already
used that name for something or need to refresh the data after making some changes you no longer
want, you can explicitly load the data using the \function{data()} function with the name of the 
data set you want.

<<rs-data-load>>=
data(Births78)
@

There is no visible effect of this command, but the \dataframe{Births78} data frame
has now been reloaded from the \pkg{mosaic} package and is ready for use.  Anything you
may have previously stored in a variable with this same name is no longer available.

\subsection{Data Frames}

Data sets are usually stored in a special structure called a \term{data frame}.

\TeachingTip{Students who collect their own data, especially if they 
store it in Excel, are unlikely to put data into the correct format
unless explicitly taught to do so.}

\begin{boxedText}
Data frames have a 2-dimensional structure.  
\medskip
\begin{itemize}
\item 
Rows correspond to 
\term{observational units} (people, animals, plants, or other objects we
are collecting data about).
\item
Columns correspond to \term{variables} (measurements collected on each 
observational unit).
\end{itemize}
\end{boxedText}
\TeachingTip{To help students keep variables and data frames straight, and to
make it easier to remember the names, we have adopted the convention that data
frames in the \pkg{mosaic} package are capitalized and variables (usually) are
not.  This convention has worked well, and you may wish to adopt it for your
data sets as well.}

The \dataframe{Births78} data frame contains three variables measured for each
day in 1978.  
There are several ways we can get some idea about what is in the \dataframe{Births78} 
data frame.

<<rs-Births78-head>>=
head(Births78)
@

<<rs-Births78-summary>>=
summary(Births78)
@
In interactive mode, you can also try
<<rs-view2,eval=FALSE,tidy=FALSE>>=
?Births78
@
to access the documentation for the data set.  This is also available in the \tab{Help} tab.
Finally, the \tab{Workspace} tab provides a list of data in the workspace.  Clicking on
one of the data sets brings up the same data viewer as 
<<rs-view1,eval=FALSE,tidy=FALSE>>=
View(Births78)
@

\authNote{add pointer to fetchData()?}

%\subsection{Getting at the Variables}
We can gain access to a single variable in a data frame using the \code{\$} operator using
the syntax
\marginnote{An alternative is to use the \function{with()} function.
}
<<rs-dollar-sign,eval=FALSE>>=
dataframe$variable
@
For example,
<<rs-Births78-births,eval=FALSE>>=
Births78$births
@
shows the contents of the \variable{births} variable in \dataframe{Births78} data set.
\marginnote{As we will see, 
there are relatively few instances where one needs to use the \texttt{\$} operator.}
Listing the entire set of values for a particular variable
isn't very useful for a large data set.  
We would prefer to compute numerical or graphical summaries.  We'll do that shortly.

\subsection{The Perils of attach()}
\Caution{Avoid the use of \function{attach()}.}
The \function{attach()} function in R can be used to make objects within data frames
accessible in \R\ with fewer keystrokes, but we strongly discourage its use, as
it often leads to name conflicts and other complications.  
The Google R Style Guide\footnote{
\url{http://google-styleguide.googlecode.com/svn/trunk/google-r-style.html}}
echoes this advice, stating that 

\begin{quotation}
\emph{The possibilities for creating errors
when using \function{attach()} are numerous. Avoid it.} 
\end{quotation}
It is far better to directly access
variables using the \code{\$} syntax or to use functions that allow you to 
avoid the \code{\$} operator.


\section{Graphical Summaries of Data}

After introducing students to the calculator functions of the \R\ console and
teaching them how to inspect a data frame, we like to get them making graphical
summaries of data.  This gives the students access to functionality where \R\
really shines (and is certainly much better than a hand-held calculator). It also 
begins to develop their ability to interpret graphical representations of
data, to think about distributions, and to pose statistical questions.

\subsection{Lattice Graphics}

There are several ways to make graphs in \R.  One approach is a system called
\pkg{lattice} graphics.   Whenever the \pkg{mosaic} package is loaded, the \pkg{lattice}
package is also loaded.  One of the attractive aspects of 
\pkg{lattice} plots is that they make use of a \term{formula interface} 
similar to that used for numerical summaries (using \pkg{mosaic}) and modeling.

All the plots we need can be created with essentially the same syntactic structure:

\TeachingTip{Emphasize repeatedly the commonalities between the various commands that
use this formula interface.}
<<rs-formula-interface, eval=FALSE, echo=TRUE, tidy=FALSE>>=
plotname( y ~ x | z, data=dataframe, 
                     groups=grouping_variable, ...)
@
\begin{itemize}
\item
Here are the names of several \pkg{lattice} plots:
\begin{itemize}
	\item \function{dotPlot()} (notice the capital P)
\footnote{\texttt{dotPlot()} is in the \pkg{mosaic} package and 
was created because \texttt{dotplot()} in
the \texttt{lattice} package makes something different from what we call a dot plot.}
\item \function{histogram()} or \function{xhistogram()}  (for histograms)
	\footnote{\function{xhistogram()} is a \pkg{mosaic} function that adds some 
	extra functionality to \function{histogram()}.}
\item \function{densityplot()}  (for density plots)
\item \function{freqpolygon()}  (for frequency polygons)
\item \function{bwplot()}  (for boxplots)
\item \function{xyplot()}  (for scatter plots)
\item \function{qqmath()}  (for quantile-quantile plots)
\end{itemize}
\item
\variable{x} is the name of the variable that is plotted along the horizontal 
($x$) axis.
\item
\Caution{Even when \variable{y} is missing, the \texttt{\~} is still mandatory.}%
\variable{y} is the name of the variable that is plotted along the vertical ($y$) 
axis.  (For some plots, such as histograms, this slot is empty because \R\ computes 
these values from the values of \variable{x}.)
\item
\variable{z} is a conditioning variable used to split the plot into 
multiple subplots called \term{panels}.
\item
\variable{grouping_variable} is used to display different groups differently
(different colors or symbols, for example) within the same panel.
\item
\variable{...} There are many additional arguments to these functions that let you
control just how the plots look.  (But we'll focus on the basics for now.)
\end{itemize}

%\subsection*{Some Examples}

\subsection{The shape of a distribution: Histograms and their kin}

A number of plots can be used to visualize the ``shape'' of a distribution, including
dot plots, histograms, density plots and frequency polygons.  Of these, the histogram
is probably the most commonly used, but there are situations when one of the others
is a better alternative.  Each can be created in \R\ using a simple command structure
<<eval=FALSE>>=
plotname(~ x, data = ...)
@
Since for each of these plots the values along the $y$ axis are computed rather than
provided in the data, the \variable{y} slot in the formula is empty.

\medskip
\subsubsection{Dot plots: \texttt{dotPlot()}}

A \term{dot plot} represents each value of a quantitative variable with a dot.  The values
are rounded a bit so that the dots line up neatly, and dots are stacked up into little
towers when the data values cluster near each other.  Dot plots are primarily used with 
modestly sized data sets and can be used as a bridge to the other plots, where there is
no longer a direct connection between a component of the plot and an individual observation.

Here is an example using the sepal lengths recorded in the \dataframe{iris} data set.
<<rs-dotPlot,cache=FALSE,fig.width=5,fig.height=3.0>>=
# n = 30 gives approx 30 columns
dotPlot(~ Sepal.Length, data=iris, n=30)    
@
We can use a conditional variable to give us separate dot plots for each of the three
species in this data set.
<<rs-dotPlot-condB,tidy=FALSE,cache=FALSE,out.width="\\textwidth",fig.width=6>>=
dotPlot(~ Sepal.Length | Species, data=iris, n=20, 
         cex=.6,        # cex used to shrink the dots a bit
         layout=c(3,1)) 
@

\medskip
\subsubsection{Histograms: \texttt{xhistogram()}}

\term{Histograms} are a lot like dot plots, but the towers of dots are replaced by vertical bars.
Again the \variable{y} component of the formula is empty since we let \R\
compute the heights of the bars
<<rs-iris-histogram,cache=TRUE,fig.width=6,out.width=".9\\textwidth">>=
# n= 20 gives approx. 20 bars
xhistogram(~ Sepal.Length, data=iris, n=20)       
@
We can use a conditional variable to give us separate histograms for each species.
\marginnote{This reveals the true story of the data -- the distribution of sepal
length is different for the different species of iris.}

<<rs-iris-histogram-cond,cache=TRUE,tidy=FALSE,fig.width=6,out.width=".9\\textwidth">>=
xhistogram(~ Sepal.Length | Species, data=iris, n=20, 
		   layout=c(3,1))  # 3 columns (x) and 1 row (y) 
@
In lattice lingo, the three subplots are called \term{panels} and the labels at the
top are called strips.  
%(Strips can be placed on the left side if you prefer.)

\medskip
\subsubsection{Frequency polygons: \texttt{freqpolygon()}}

\term{Frequency polygons} and \term{density plots} provide alternatives to histograms
that make it easier to overlay the representations of multiple subsets of the data.
A frequency polygon is created from the same data summary (bins and counts) as a histogram, 
but instead of representing each bin with a bar, it is represented by a point 
(at the center of the where the top of the histogram bar would have been).  
\Caution{The \dataframe{faithful} data set contains similar data, but the 
variable names in that data frame are 
poorly chosen.  The \dataframe{geyser} data set in the \pkg{MASS}
package has better names and more data.}
These points are then connected with line segments.
Here is an example that shows the distribution of Old Faithful eruptions times
from a sequence of observations 

<<>>=
require(MASS)
freqpolygon( ~ duration, data=geyser, n=15)
@
\TeachingTip[-1.5in]{Point out that an interesting feature of this distribution is its clear 
bimodality.
In particular, the mean and median eruption time are not a good measures of the duration of a  
``typical'' eruption since almost none of the eruption durations are near the mean and median.}
Numerically, the data are being summarized and  represented in exactly the same way as for 
histograms, but visually the horizontal and vertical line segments of the histogram are 
replaced by sloped line segments.  
<<echo=FALSE>>=
xhistogram( ~ duration, data=geyser, n=15, col="lightskyblue")
ladd( panel.freqpolygon(geyser$duration, n=15) )
@
This may give a more accurate visual representation in some 
situations (since the distribution can ``taper off'' better).  More importantly, it makes 
it much easier to overlay multiple distributions.
<<>>=
freqpolygon( ~ Sepal.Length, data=iris, groups=Species, 
               ylim=c(0,65))
@

\medskip
\subsubsection{Density plots: \texttt{densityplot()}}

\term{Density plots} are similar to frequency polygons, but the piecewise linear
representation is replaced by a smooth curve.  
<<>>=
densityplot( ~ Sepal.Length, data=iris, groups=Species)
@
Beginners do not need to know the details
of how that smooth curve is generated, but should be introduced to the \option{adjust}
argument which controls the degree of smoothing.  It is roughly equivalent to choosing 
wider or narrower bins for a histogram or frequency polygon.  The default value is 1.
Higher values smooth more heavily; lower values, less so.
<<tidy=FALSE>>=
densityplot( ~ Sepal.Length, data=iris, groups=Species, 
             adjust=3)
densityplot( ~ Sepal.Length, data=iris, groups=Species, 
             adjust=1/3)
@

\medskip
\subsubsection{The Density Scale}

There are three scales that can be used for the plots in the preceding section: 
\code{count}, 
\code{percent}, 
and \code{density}.  
Beginning students will be most familiar with the \code{count} scale and perhaps also 
the \code{percent} scale, but most will not have seen the \code{density} scale.
The density scale captures the most important aspect of all of these plots

\begin{boxedText}
	\centerline{Area is proportional to frequency.}
\end{boxedText}

\noindent
The density scale is chosen so that the constant of proportionality is 1, in which case we have
\begin{boxedText}
	\centerline{Area equals proportion.}
\end{boxedText}
\TeachingTip{Create some histograms or frequency polygons with a density scale and see
if your students can determine what the scale is.  Choosing convenient bin widths (but not 1)
and comparing plots with multiple bin widths and multiple scale types can help them
reach a good conjecture about the density scale.}
This is the only scale available for \function{densityplot()} and is the most suitable 
scale if one is primarily interested in the \emph{shape} of the distribution.  The vertical scale
is affected very little by the choice of bin widths or \option{adjust} multipliers.
It is also the appropriate scale to use when overlaying a density function.
<<fig.width=6,out.width="\\textwidth", tidy=FALSE>>=
xhistogram( ~ Sepal.Length | Species, data=iris, 
                                      fit="normal" )
@

The other scales
are primarily of use when one wants to be able to read off bin counts or percents from the plot.



\medskip
\subsection{Boxplots: \texttt{bwplot()}}

Boxplots are constructed in much the same manner as the plots in the previous section:
<<rs-iris-bwplot>>=
bwplot(~ Sepal.Length, data=iris)
@

As we did for histograms, we can use conditioning to 
show boxplots for multiple groups within the data set:
\Caution[.2in]{This is not a particularly good plot for displaying this information.
We'll illustrate a better way in a moment.}
<<rs-iris-bwplot-cond,cache=TRUE,fig.width=7,fig.height=2,out.width=".9\\textwidth">>=
bwplot(~ Sepal.Length | Species, data=iris, layout=c(3,1))
@
But there are better ways to do this.
\InstructorNote{The boxplots are vertical when the categorical variable is on the 
right hand side of the \tilde.}
<<label="rs-iris-bwplot-2d">>=
bwplot(Sepal.Length ~ Species, data=iris)
@
\InstructorNote{The boxplots are horizontal when the categorical variable is on the 
left hand side of the \tilde.}
<<label="rs-iris-bwplot-2dmore">>=
bwplot(Species ~ Sepal.Length, data=iris)
@
%\vspace{-12mm}
\Caution[-1in]{If numbers are used to label the categories 
of a categorical variable, \R\ will consider the data to be quantitative.
You can convert numerical values into a categorical factor by
wrapping it in the function \function{factor()}, e.g., \code{factor(x)}.
}


\subsection{Scatterplots: \texttt{xyplot()}}

Scatterplots are made with \function{xyplot()}.  The formula and modeling interface is used in the same manner as before.
Just remember that the ``$y$ variable'' comes first.  (Its label is also farther left on 
the plot, if that helps you remember.)
<<rs-iris-xyplot,cache=TRUE>>=
xyplot(Sepal.Length ~ Sepal.Width, data=iris)
@
Again, we can use conditioning to make a panel for each species.
<<rs-iris-xyplot-cond,tidy=FALSE,cache=TRUE,fig.width=6,out.width=".8\\textwidth">>=
xyplot(Sepal.Length ~ Sepal.Width | Species, data=iris,
  layout=c(3,1)) # layout controls number of columns and rows
@
Even better (for this example), we can use the \option{groups} argument to indicate the 
different species using different symbols on the same panel.
<<rs-iris-xyplot-groups,cache=TRUE,tidy=FALSE>>=
xyplot(Sepal.Length ~ Sepal.Width, groups=Species, 
  auto.key=TRUE, data=iris)
@

\subsection{Saving Your Plots}

There are several ways to save plots in \RStudio, but the easiest is probably the following:
\marginnote{You can save all of this exporting and copying and pasting if you use RMardown, 
or \pkg{knitr}/\LaTeX\ to prepare your documents.}
\begin{enumerate}
\item
In the \tab{Plots} tab, click the ``Export'' button.
\item
Copy the image to the clipboard using right click.
\item
Go to your document (e.g. Microsoft Word) and paste in the image.
\item
Resize or reposition your image as needed.
\end{enumerate}
The \function{pdf()} function can be used to save plots as pdf files.  See 
the documentation of this function for details and links to functions that 
can be used to save graphics in other file formats.


\section{Numerical Summaries}
Numerical summaries are computed using a syntax that matches the 
\pkg{lattice} graphics syntax.
Most of the numerical summaries already familiar to you have obvious names.  
Here are a few examples.  
\authNote{add iqr() once an aggregating version is in the package}%
\authNote{NH wants a discussion of \function{with()} and the use of 
\texttt{\$} here.  RJP says keep it simple.}%
\marginnote{In the current version of the \pkg{mosaic} package,
the \tilde\ can be omited in the one-variable numerical summary functions.  This is 
not true for the \pkg{lattice} plots, so we recommend that you use the \tilde\ and
be consistent across multiple functions.}

<<rs-numerical-summaries>>=
mean(~ births, data=Births78)
median(~ births, data=Births78)
sd(~ births, data=Births78)
max(~ births, data=Births78)
min(~ births, data=Births78)
@
The \function{favstats()} function in the \pkg{mosaic} package computes several numerical 
summaries all at once.
<<>>=
favstats(~ births, data=Births78)
@

The formula interface for these functions provided by the \pkg{mosaic} package
\begin{itemize}
	\item
		Removes the need for the \code{\$} operator.

	\item
		Simplifies computing summary statistics separately in each of several groups.  For
		example,
<<>>=
# these are equivalent
mean( length ~ sex, data=KidsFeet )
mean( ~ length | sex, data=KidsFeet )
@

	\item
		Makes computing numerical summaries syntactically identical to creating 
		graphical summaries with \pkg{lattice} or fitting linear models.
\end{itemize}

\begin{problem}
What is the average (mean) \emph{width} of the sepals in the \dataframe{iris} data set?
\end{problem}
\begin{solution}
<<>>=
mean(Sepal.Width, data=iris)
@
\end{solution}

\begin{problem}
Determine the average (mean) sepal width for each of the three species in the \dataframe{iris} data set.
\end{problem}
\begin{solution}
<<>>=
mean(Sepal.Width ~ Species, data=iris)
@
\end{solution}


\subsection{Tabulating Categorical Data}
The Current Population Survey (CPS) is used to supplement census information
between census years. The \dataframe{CPS85} data set consists of a random
sample of persons from the CPS, with information on wages and other
characteristics of the workers, including sex, number of years of education,
years of work experience, occupational status, region of residence and union
membership.

\begin{widestuff}
<<include=FALSE>>=
oldOpts <- options(width=100)
@
<<>>=
head(CPS85, 3)
@
\end{widestuff}

%\newthought{Frequency and Contingency Tables}
\begin{widestuff}
Categorical variables are  often summarized in a table.  
\R\ can make a table for a categorical variable using \function{tally()}.
\end{widestuff}

\begin{widestuff}
<<rs-table1>>=
tally(~ race, CPS85)
tally(~ sector, CPS85)
@
\end{widestuff}

\begin{widestuff}
If we prefer to have the results presented as proportions or percents, we 
just have to ask.
\end{widestuff}

\begin{widestuff}
<<rs-table2>>=
tally( ~ sector, CPS85, format='perc')
tally( ~ sector, CPS85, format='prop')
@
\end{widestuff}
%Alternatively, we can use \verb!table()!, \verb!proptable()!, and
%\verb!perctable()!  to make tables of counts, proportions, or percentages,
%respectively.

%\newthought{Cross-Tabulation with \texttt{xtabs()}}
\begin{widestuff}
We can make a \term{cross-table} 
(also called a \term{contingency table} or a \term{two-way table}) 
summarizing this data with \function{tally()}.  
This often provides a useful display of the relationship between
two categorical variables.
\end{widestuff}

\begin{widestuff}
<<rs-xtabs>>=
tally(~ race + sector, CPS85)   # 2-way cross-table
@
\end{widestuff}

\begin{widestuff}
Alternatively, we can select one of our categorical variables to be 
a conditional variable.  The report is then done using proportions by default.
\end{widestuff}

\begin{widestuff}
<<>>=
tally(~ race | sector, CPS85)   # conditional on sector
tally(~ sector | race, CPS85)   # conditional on race
@
\end{widestuff}

<<include=FALSE>>=
options(oldOpts)
@

\subsection{Graphing Categorical Data}

The \pkg{mosaic} function \function{bargraph()} can 
display these tables as bar graphs.
<<rs-bargraph1a,tidy=FALSE>>=
bargraph(~ sector, data=CPS85, 
                   scales=list(x=list(rot=45)))
@
<<rs-bargraph2a>>=
# horizontal bars
bargraph(~ sector, data=CPS85, horizontal=TRUE)  
@

As with the other lattice plots, we can add grouping or conditioning to 
our plot.
<<rs-bargraph3a,tidy=FALSE>>=
bargraph(~ sector, data=CPS85, groups=race, 
                   scales=list(x=list(rot=45)))
@
<<rs-bargraph3amore,tidy=FALSE>>=
bargraph(~ sector | race, data=CPS85, 
                          scales=list(x=list(rot=45)))
@


Bar graphs can also be used to display two-way tables.  
<<rs-barchart3aa,tidy=FALSE>>=
bargraph( ~ sector, groups=race, data=CPS85,
                    scales=list(x=list(rot=45)))
@



\iffalse
Just as bar charts are used to display the distribution of one categorical
variable,  \pkg{mosaic} plots can do the same for cross tables.
The \function{mosaic()} function (from the \pkg{vcd} package) is not a \pkg{lattice} plot, 
but it does use a similar formula interface.  

<<rs-mosaic1,fig.width=4,fig.height=2>>=
require(vcd)                         # load the visualizing categorical data package
mosaic(~ sex + union, CPS85)
@
We see that there are more non-union women than we would expect just from
the marginal distribution of union status and gender.

\Caution{The \function{mosaic()} function has nothing to do with 
the \pkg{mosaic} package, they just happen to share the same name.}%

Alternatively, we can send \function{mosaic()} the output of \function{xtabs()}:
<<rs-mosaic2,fig.keep="none">>=
mosaic(xtabs(~ sex + union, CPS85))  # non-whites are more likely to be unionized
@
\FoodForThought{Neither \function{mosaic()} nor the similar \function{mosaicplot()}
are as clever as one could hope.  In particular, without some extra customization,
both tend to look bad if the levels of the variables have long names.
\function{mosaic()} plots also always stay square.}


Alternatively,
we can send our own hand-made table (although the output isn't quite as nice without some
extra effort we won't discuss just now):
<<rs-mosaic3,fig.width=6,fig.height=2.5>>=
mosaic(mycrosstable)
@
\fi



\begin{problem}
The \dataframe{Utilities2} data set in the \pkg{mosaic} package contains information
about the bills for various utilities at a residence in Minnesota collected over a number of years.
Since the number of days in a billing cycle varies from month to month, variables 
like \vn{gasbillpday} (\dataframe{elecbillpday}, etc.) contain the gas bill (electric bill, etc.) 
divided by the number of days in the billing cycle.
\begin{enumerate}
\item Use the documentation to determine what the \vn{kwh} variables contains.
\item
Make a scatter plot of \dataframe{gasbillpday} vs. \dataframe{monthsSinceY2K} using the command
<<rs-gasbill,fig.keep="none", tidy=FALSE>>=
xyplot(gasbillpday ~ monthsSinceY2K, data=Utilities2, 
                     type='l')        # the letter l
@
\item[]
What pattern(s) do you see?
\item
What does \option{type='l'} do?  Make your plot with and without it.  Which is easier to read
in this situation?
\item
What happens if we replace 
\option{type='l'} with 
\option{type='b'}?
\item
Make a scatter plot of \vn{gasbillpday} by \vn{month}.   
What do you notice?

\item
Make side-by-side boxplots of \vn{gasbillpday} by \vn{month} using the \dataframe{Utilities2}
data frame.   
What do you notice?

Your first try probably won't give you what you expect.  The reason is that month is coded
using numbers, so \R\ treats it as numerical data.  We want to treat it as categorical data.
To do this in \R\, use \variable{factor(month)} in place of \variable{month}.  
\R\ calls categorical data a \term{factor}.

\item
Make any other plot you like using this data.  Include both a copy of your plot and a 
discussion of what you can learn from it.
\end{enumerate}
\end{problem}

\begin{problem}
The table below is from a study of nighttime lighting in infancy and 
eyesight (later in life).  
% latex table generated in R 2.12.1 by xtable 1.5-6 package
% Fri Feb  4 15:46:48 2011
\begin{center}
\begin{tabular}{rrrr}
  \hline
 & no myopia & myopia & high myopia \\ 
  \hline
darkness & 155 & 15 & 2 \\ 
  nightlight & 153 & 72 & 7 \\ 
  full light & 34 & 36 & 3 \\ 
   \hline
\end{tabular}
\end{center}

\begin{enumerate}
%\item
%Do you think this was an experiment or an observational study?  Why?
\item
Recreate the table in \R. %Copy and paste the results into your Word document.
\item
What percent of the subjects slept with a nightlight as infants?

There are several ways to do this.  You could use \R\ as a calculator to do the arithmetic.
You can save some typing if you use the function \function{tally()}.  See
\code{?tally} for documentation.
%If you just want row and column totals added to the table, see \verb!mar_table()!
%in the \verb!vcd! package.
\item Create a graphical representation of the data.  What does this plot reveal?
\end{enumerate}
\end{problem}

\subsection{Working with Pretabulated Data}

Because categorical data is so easy to summarize in a table, 
often the frequency or contingency tables are given instead.
You can enter these tables manually using a combination
of \function{c()}, \function{rbind()} and \function{cbind()}:
\TeachingTip{This is an important technique if you use a text book
that presents categorical data in tables.}

<<rs-make-table>>=
myrace <- c( NW=67, W=467 )       # c for combine or concatenate
myrace
@

\label{R:make-xtabs}%
<<rs-make-xtabs, tidy=FALSE>>=
mycrosstable <- rbind(               
  NW = c(clerical=15, const=3, manag=6,  manuf=11, 
		 other=5,  prof=7, sales=3, service=17),
  W  = c(82,17,49,57,63,98,35,66)    
			  )
mycrosstable
@
Replacing \function{rbind()} with \function{cbind()} will allow you to give the data
column-wise instead.
\TeachingTip{If plotting pre-tabulated categorical data is important, you probably
want to provide your students with a wrapper function to simplify all this.  We generally
avoid this situation by provided the data in raw format or by presenting an analysing 
the data in tables without using graphical summaries.}

This arrangement of the data would be sufficient for applying the Chi-squared test, but
it is not in a format suitable for plotting with \pkg{lattice}.
Our cross table is still missing a bit of information -- the names of the variables being
stored.  We can add this information if we convert it to a table
<<>>=
class(mycrosstable)
mycrosstable <- as.table(mycrosstable)
# mycrosstable now has dimnames, but they are unnamed
dimnames(mycrosstable)
# let's add meaninful dimnames
names(dimnames(mycrosstable)) <- c('race', 'sector')
mycrosstable
@

We can use \function{barchart()} instead of \function{bargraph()} to plot data 
already tabulated in this way, but first we need yet one more transformation.
<<>>=
head(as.data.frame(mycrosstable))
@

<<tidy=FALSE>>=
barchart( Freq ~ sector | race,
          data=as.data.frame(mycrosstable),
          auto.key=list(space='right'),
          scales=list(x=list(rot=45))
		  )
@
<<tidy=FALSE>>=
barchart( Freq ~ sector, groups=race, 
          data=as.data.frame(mycrosstable),
          auto.key=list(space='right'),
          scales=list(x=list(rot=45))
		  )
@


\section{Using Your Own Data}
\label{sec:usingdata}
\TeachingTip{Start out using data from packages and focusing on what \R\ can
do with the data.  Later, once students are familiar 
with \R\ and understand the format required for data,
teach students how to import their own data.}
Eventually, students will want to move from using example data sets in \R\ packages
to using data they find or collect themselves.  When this happens will depend on 
the type of students you have and the type of course you are teaching.

\R\ provides the functions \function{read.csv()} (for comma separated values files),
\function{read.table()} (for white space delimited files) and \function{load()}
(for loading data in \R's native format).
The \pkg{mosaic} package includes a function called \function{read.file()} that uses 
slightly different default settings and infers whether it should use \function{read.csv()},
\function{read.table()}, or \function{load()} based on the file name.  

Since most software packages can export to csv format, this has become a 
sort of \emph{lingua fraca} for moving data between packages.  Data in excel, for example,
can be exported as a csv file for subsequent reading in \R.  
\Caution{There is a conflict between the \function{resample()} functions in
\pkg{gdata} and \pkg{mosaic}.  If you want to use \pkg{mosaic}'s \function{resample()},
be sure to load \pkg{mosaic} \emph{after} you load \pkg{gdata}.}
If you have python installed on your system, you can also use
\function{read.xls()} from the \pkg{gdata} package to read read directly from
Excel files without this extra step.

Each of these functions accepts a URL as well as a file name, which provides an
easy way to distribute data via the Internet:
\authNote{Should we change URLs to something at mosaic-web.org?}
<<tidy=FALSE>>=
births <- 
  read.table('http://www.calvin.edu/~rpruim/data/births.txt', 
              header=TRUE)
head(births) # live births in the US each day of 1978.
@
We can omit the \option{header=TRUE} if we use \function{read.file()}
<<tidy=FALSE>>=
births <- 
  read.file('http://www.calvin.edu/~rpruim/data/births.txt')
@
%\Rstudio\ will help you import your own data.  To do so use the ``Import Dataset" 
%button in the \tab{Workspace} tab.  You can load data from text files, from the web, or from
%google spreadsheets.   

\subsection{Importing Data in \RStudio}
\InstructorNote{Even if you use \RStudio\ GUI for interactive work, you 
will want to know how to use functions like \function{read.csv()} for working
in RMarkdown, or \pkg{knitr}/\LaTeX\ files.}
The \RStudio\ interface provides some GUI tools for loading data.
If you are using the \RStudio\ server, you will first need to upload the data
to the server (in the \tab{Files} tab), and then import the data into your \R\ 
session (in the \tab{Workspace} tab).  
\TeachingTip{Remind students that the 2-step process (upload, then import)
works much like images in Facebook.  First you upload them to Facebook, and once 
they are there you can include them in posts, etc.}%
If you are running the desktop version, the upload step is not needed.



\subsection{Developing Good Data Habits}
However you teach students to collect and import their data, students will need to 
be trained to follow good data organization practices:
\begin{itemize}
\item Choose good variables names.
\item Put variables names in the first row.
\item Use each subsequent row for one observational unit.
\item Give the resulting data frame a good name.
\end{itemize}
Scientists may be disappointed that \R\ data frames dont' keep track of additional information, 
like the units in which the observations are recorded.  This sort of information should be 
recorded, along with a description of the protocols used to collect the data, observations
made during the data recording process, etc.  This information should be maintained in a 
lab notebook or a \term{codebook}.



\begin{problem}
Enter the following small data set in an Excel or Google spreadsheet and import the 
data into \Rstudio.

\begin{center}
\includegraphics[width=.75\textwidth]{images/GoogleSpreadsheet}
\end{center}
\end{problem}

%\subsection{Putting Data Into a Package}
%
%It is not that difficult to take a collection of csv files (a format available for many books)
%and put them all into a package.
%The \verb!abd! package contains data sets from \textit{The Analysis of Biological Data}, for example.  
%Kevin Middleton and Randall Pruim contacted the authors and obtained permission to 
%build and disseminate this package.
%
%The \verb!abdData()! function in \verb!abd! makes it easy to map examples and exercises in that book to 
%data frame names in the \verb!abd! package.
%
<<rs-findData-human,eval=FALSE,echo=FALSE>>=
abdData('human')         # all data sets with 'human' in the name
@
%
<<rs-findData-2,eval=FALSE,echo=FALSE>>=
abdData(2)               # all data sets in chapter 2
@
%
%For information on how to create such packages, consult the \textit{Writing R Extensions} manual
%on CRAN.

\newpage
\section{Review of \R\ Commands}


\begin{widestuff}
Here is a brief summary of the commands introduced in this chapter.

<<tidy=FALSE,results='hide',fig.keep="none">>=
require(mosaic)                        # load the mosaic package
answer <- 42                           # store the number 42 in a variable named answer
log(123); log10(123); sqrt(123)        # some standard numerical functions
x <- c(1,2,3)                          # make a vector containing 1, 2, 3 (in that order)
data(iris)                             # (re)load the iris data set
names(iris)                            # see the names of the variables in the iris data
summary(iris)                          # summarize each variables in the iris data set
str(iris)                              # show the structure of the iris data set
head(iris)                             # first few rows of the iris data set

mydata <- read.table("file.txt")       # read data from a text file
mydata <- read.csv("file.csv")         # read data from a csv file
mydata <- read.file("file.txt")        # read data from a text or csv file

tally( ~ sector, data=CPS85 )          # frequency table
tally( ~ sector + race, data=CPS85 )   # cross tabulation of sector by race   
mean( ~ age, data = HELPrct )          # mean age of HELPrct subjects
mean( ~ age | sex, data = HELPrct )    # mean age of male and female HELPrct subjects
mean( age ~ sex, data = HELPrct )      # mean age of male and female HELPrct subjects
median(x); var(x); sd(x);              # more numerical summaries
quantile(x); sum(x); cumsum(x)         # still more summaries
favstats( ~ Sepal.Length, data=iris )  # compute favorite numerical summaries

dotPlot( ~ Sepal.Length | Species, data=iris )             # dot plots for each species
xhistogram( ~ Sepal.Length | Species, data=iris )          # histograms (with eXtra features)
densityplot( ~ Sepal.Length, groups = Species, data=iris ) # overlaid densityplots
freqpolygon( ~ Sepal.Length, groups = Species, data=iris ) # overlaid frequency polygons
bwplot( Sepal.Length ~ Species, data = iris )              # side-by-side boxplots
xyplot( Sepal.Length ~ Sepal.Width | Species, data=iris )  # scatter plots for each species
bargraph( ~ sector, data=CPS85 )                           # bar graph
qqmath( ~ age | sex, data=CPS85 )                          # quantile-quantile plots
@

\end{widestuff}
\newpage
\section{Exercises}

%For these problems, create a single Word document containing all of your work.

\shipoutProblems



