---
title: "How I teach SBI using R"
author: "R Pruim"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_height: 3
    fig_width: 4
    size: small
  pdf_document: default
---

```{r, startup, include=FALSE}
require(mosaic)
trellis.par.set(theme=col.mosaic())
set.seed(12345)
require(mosaic)
```

<!--
I've often been asked how I have students perform simulation 
based inference (SBI) using R.  The short answer is that I use the 
`mosaic` package because it keeps students' attention on the right
parts of the task (and off of the inessentials).  At least, that
was the goal when my co-authors Danny Kaplan and Nick Horton and I 
created this package.
-->

I'm not writing to convince you that you *should* use R to teach simulation based 
inference (SBI).
<!--
<del>
Choice of technology depends on many things, including short- 
and long-term learning objectives for and of the students, local infrastructure,
instructor familiarity, and budget.  R is a popular choice because it is free
and powerful enough to keep up with students as they progress through a program.
It is also a marketable skill.  But R can be daunting, especially if the instructor
is unfamiliar with R.  And, like any language, it can be used well or poorly.
</del> -->
My goal is to convince you that you *can* use R for SBI, even with
students (and instructors) who have never used R before. 
Along the way I'll mention
some guiding principles and illustrate some tools that 
my colleagues Danny Kaplan and Nick Horton and I have assembled in the 
[`mosaic` R package](https://github.com/ProjectMOSAIC/mosaic/blob/master/README.md) 
to make SBI (and EDA and traditional inference procedures) much easier.


If you are unfamiliar with R, this post will be too short to give you 
a good introduction, but I hope it will make you curious enough to learn more. 
See the references for places to learn more about R and teaching with R.

### Less Volume, More Creativity

The biggest key to using R well is to provide a lot of creative oppurtunity
with as little R as possible.  There can be a lot of ways to skin a cat in R,
what you need is a systematic approach that allows you to economically 
acheive your goals.  If technology is the most difficult thing in your course, 
then your technology is too hard or your questions are too simple (probably both).
On the other hand, if your students are able to guess how to do new things
in R before you show them, then you will know you are on the right track.

<!--
<del>
If you have used R before, I recommend the following exercise: Make a list of
all of the R commands you have introduced in your course. 
Organize them into themes.  Eliminate the unnecessary.  Replace one command with
another if it reduces the overall complexity of the R you are teaching and still
gets the job done.  Compare your list to 
[someone else's list](https://github.com/ProjectMOSAIC/mosaic/blob/master/vignettes/MinimalR.pdf)
and see if that leads you to adjust your list.
</del>

<del>
If you are going to do SBI, make sure that your non-SBI tools and your SBI tools
play well together.
</del>
-->

<!--
### <del>Don't teach programming</del>

<del>
Nearly everything I do with R in my courses involves simple, one-line, declarative
R statements. You won't see any `if()` statements or `for()` loops in my class -- not even for SBI. I focus on getting students to ask two questions:
</del>

 1. <del>What do I want R to do?</del>
 2. <del>What does R need to know to do that for me?</del>

<del>
If students can answer those questions, we're typically not far from writing 
down the R syntax to make it happen.  If they can't answer those questions,
then it doesn't matter what technology we are using, we have other work to do first.
</del>
-->

<!--
### Doing randomization tests 

The R part of conducting hypothesis tests generally boils down
to this:

 1. Compute a test statistic from the data.
 
    Often this will involve a numerical summary function 
    like `mean()` or a modeling function like `lm()`.  
    The `mosaic` package gives all these (and graphical summaries, too) 
    a common interface 
    so that they can be learned as a single cognitive template.
 
    *perhaps insert template graphic here*
 
 2. Figure out how to simulate a test statistic computed from
    random data assuming the null hypothesis is true. 

    The main functions I use to introduce randomness are
    `rflip()` (for "coin tosses"), `shuffle()` (for rearranging the order), 
    and `resample()` (for sampling with replacement). 
 
 3. Do that a lot of times.
 
    If we can do it once, then the `do()` function will let us do it 
    lots of times.
 
 4. Compare the test statistic from step 1 to the distribution in step 3.
 
    The same numerical and graphical summary functions used
    in step 1 can be used here because we make sure that the 
    output from step 3 is a data frame, just like the original
    sample data was.
 
Altogether, the R-related cognitive load for students is

  * [a template for graphical and numerical summaries](http://cran.r-project.org/web/packages/mosaic/vignettes/LessVolume-MoreCreativity.html), which is needed for non SBI things as well
  * `rflip()`, `shuffle()` and `resample()` for generating random data
  * `do()` for repeating things
 
These can be combined to perform a wide variety of tests.  That's a lot 
of creativity for little volume.

In what follows, I will focus primarily on step 3, generating the randomization 
distribution since the other steps involve components that would need to be 
in place for any course using R to analyse data.
-->

## An example: The Lady Tasting Tea

I typically introduce inference on the first day doing a hypothesis test 
for a  proportion "informally".  Often I use some variation on 
[Fisher's Lady Tasting Tea](http://en.wikipedia.org/wiki/Lady_tasting_tea) 
example because I find that students remember it well and I can refer back 
to it as a motivating example for the rest of the semester.  
I find the example works equally well
in an Intro Stats course an in my upper level courses, and I like that it 
connects them in a small way to the history of the discipline. 

Let's see how we can test whether the lady is just guessing given that 
she correctly identifies 9 of 10 randomly prepared cups of tea.

Guessing is like flipping a coin, so `mosaic` provides a coin flipper:

```{r}
rflip()    # think random flip
```
 
Since our design calls for 10 cups of tea, we need to flip 10 coins.
Fortunately, we don't have to use `rflip()` ten times and record 
the results manually.  We just ask for 10 flips.
 
```{r}
rflip(n = 10)
```
 
Now we need to do this a lot of times.  The `do()` function provides 
an easy syntax and is clever about how it stores the results, in this
case storing the number of flips, number of heads, number of tails,
and proportion that are heads.

```{r eval=FALSE}
do(1000) * rflip(n = 10)   # do 1000 times 
```
```{r echo=FALSE}
do(3) * rflip(n = 10)
```

```
## <997 lines omitted>
```

Of course, we should look at this some other way than by having 
it all scroll past on our screen.  Let's save the results and 
look at numerical and graphical sumamries.

```{r}
GuessingLadies <-
  do(1000) * rflip(n = 10)  # simulate 1000 guessing ladies
tally(~heads, data = GuessingLadies)
histogram(~heads, data = GuessingLadies, width = 1)
```

Based on our simulation, it appears that someone can get 9 or 10 just by
guessing only about `r sum(GuessingLadies$heads >= 9) * 100 / 1000`% of the time.

If we want to have a more precise estimate of this proportion (the p-value), 
we can increase the number of times we `do()` things.  
We could also 999 (or 9999) instead of 1000 and 
include the observed statistic in the null distribution as recommended
the article Tim Hesterberg previews in his 
[SBI blog post](https://www.causeweb.org/sbi/?p=521#more-521). 

### Grand Tour of Randomization Distributions

If we want to test for a different proportion (e.g., .25), we simply tell `rflip()`
the probability of obtaining heads (`p`) and the size of our sample (`n = 100` in 
the example below):

```{r, proportion}
Proportion.null <- do(1000) * rflip(n = 100, p = 0.25)   
```
```{r, proportion.out, echo=FALSE}
head(Proportion.null, 2)
```
```
<998 rows omitted>
```

Null distributions for permutation tests can be simulated by shuffling the 
appropriate labels.  Here are examples for tests involving the difference 
bewtween two proportions, the difference between two means, or 
a linear model:

```{r}
Galton2 <- Galton %>% group_by(family) %>% sample_n(1)  # one from each family
Null1 <- do(1000) * diffprop(homeless ~ shuffle(sex),       data = HELPrct)
Null2 <- do(1000) * diffmean(  height ~ shuffle(sex),       data = Galton2)
Null3 <- do(1000) *       lm(     age ~ shuffle(substance), data = HELPrct)  # ANOVA
Null4 <- do(1000) *       lm(  father ~ shuffle(mother),    data = Galton2)  # regression
```

Looking at the first few rows of `Null4`, we see that `do()` extracts and records
several useful bits of information about a linear model:

```{r, echo=FALSE}
head(Null4, 3)
```

We can use the slope (labeled `mother`), $r^2$, or $F$ as our test statistic.

One null distribution that is somewhat more challenging is the null distribution
for a test of a single mean.  The challenge is to determine how to simulate data
with a mean equal to that of the null hypothesis.  This can be done non-paremtrically
by shifting.  I find it simplest to do this by changing $H_0: \mu = 98.6$ into
$H_0: \mu - 98.6 = 0$ and sampling with replacement from the population:

```{r, message=FALSE}
require(Lock5withR)
Null <- do(1000) * mean( ~ (BodyTemp - 98.6), data = resample(BodyTemp50))
```

Both the shifting and the introduction of sampling with replacement may be more 
distracting than they are worth since a confidence interval for a mean is 
generally more useful anyway, but it rounds out our tour.


### Bootstrap too

Generating bootstrap distribution to form confidence intervals is similar.
Typically, instead of shuffling a variable we resample the entire data
set (possibly within groups) to produce a bootstrap distribution.
Here is a bootstrap distribution for the difference in mean heights of 
men and women using Galton's data, resampling separately from the males
and females:

```{r}
HeightBySex.boot <- 
  do(1000) * diffmean( height ~ sex, data = resample(Galton, groups = sex) )
histogram(~diffmean, data = HeightBySex.boot)
```

Simple confidence intervals can be computed using percentiles or 
the bootstrap standard error, which is just the standard deviation 
of the bootstrap distribution.

```{r}
cdata(0.95, ~diffmean, data = HeightBySex.boot)  # central 95%
sd(~diffmean, data=HeightBySex.boot)
```

Eventually, I may show my students how to automate generating the confidence
intervals once the boostrap distribution has been generated:

```{r}
confint(HeightBySex.boot, method=c("percentile", "se"))
```

### Striking a Balance


I find that using the `mosaic` package keeps the focus on what is important 
(thinking about where randomization enters and why, and what to do
with the distribution once we have it)
while hiding distracting details 
(looping structures, extracting the relevant information from 
R objects, etc.).
There are other R packages 
([`resample`](http://cran.r-project.org/web/packages/resample/index.html) 
and 
[`boot`](http://cran.r-project.org/web/packages/boot/index.html), for example) 
that are faster and use more sophisticed methods, but hide some of the things 
I want students to see and think about when they are learning how simulation 
based inference works.

Altogether, the R-related cognitive load for students to do
SBI amounts to

  * [a template for graphical and numerical summaries](http://cran.r-project.org/web/packages/mosaic/vignettes/LessVolume-MoreCreativity.html), which is needed for non SBI things as well
  * `rflip()`, `shuffle()` and `resample()` for generating random data
  * `do()` for repeating things
 
These can be combined to perform a wide variety of tests.  That's a lot 
of SBI creativity for little volume.

### Additional Resources

The following resources are provided by Project MOSAIC (Danny Kaplan, Nick Horton, and Randy Pruim) for those interested in learning more about using R to teach
statistics.

  * [eCOTS 2014 Workshop: "Effective Teaching using R, RStudio, and the MOSAIC Package"](https://www.causeweb.org/ecots/ecots14/45/).
 
  * [*Less Volume, More Creativity*](http://cran.r-project.org/web/packages/mosaic/vignettes/LessVolume-MoreCreativity.html) -- an introduction to the `mosaic` package 
  emphasing the use of a common template for numerical summaries, graphical summaries, 
  and modeling.
 
  * *Randomization based Inference*
  [[view]](https://github.com/ProjectMOSAIC/mosaic/blob/master/vignettes/Resampling.pdf) 
  [[download]](https://github.com/ProjectMOSAIC/mosaic/raw/master/vignettes/Resampling.pdf) -- 
  examples of simulation based inference with `mosaic` based on the 
  2013 USCOTS Randomization Bake Off
 
 
  * *Start Teaching Statistics Using R*
 [[view]](Starting/MOSAIC-StartTeaching.pdf)
 [[download]](../../raw/master/Starting/MOSAIC-StartTeaching.pdf)
 
  * *A Student's Guide to R* 
 [[view]](StudentGuide/MOSAIC-StudentGuide.pdf)
 [[download]](../../raw/master/StudentGuide/MOSAIC-StudentGuide.pdf)
 
 * [Lock5withR](https://github.com/rpruim/Lock5withR/blob/master/README.md)
 -- a companion to *Unlocking the Power of Data* by Five Locks (with Lana Park)
 
 * [ISIwithR](https://github.com/rpruim/ISIwithR/blob/master/README.md)
 -- a companion to *Introduction to Statistical Inference* 
 by Nathan Tintle *et al* (with Lana Park)
 

### About the Author

Randall Pruim is a professor of 
mathematics and statsitics at Calvin College and the maintainer of several
R packages, including `mosaic`, `Lock5withR`, and `ISIwithR`.

<img src="images/headshot-1.jpg"  style="width: 200px;" /img>
<img src="images/headshot-2.jpg"  style="width: 200px;" /img>
