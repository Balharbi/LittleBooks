
\section{Scatterplots}
\myindex{scatterplots}%
\myindex{lowess}%
\myindex{smoothers}%
\myindex{linearity}%

We always encourage students to start any analysis by graphing their data.  
Here we augment a scatterplot
of the CESD (a measure of depressive symptoms, higher scores indicate more symptoms) and the MCS (mental component score from the SF-36, where higher scores indicate better functioning) for female subjects
with a lowess (locally weighted scatterplot smoother) line, using a circle
as the plotting character and slightly thicker line.

\InstructorNote{The lowess line can help to assess linearity of a relationship. This is added by specifying both points (using `p') and a lowess smoother.}
\Rindex{gf\_point()}%
\Rindex{shape option}%
\Rindex{size option}%
\Rindex{gf\_smooth()}%
\begin{center}
<<HELPrct-xyplot,fig.height=3,tidy=FALSE,message=FALSE>>=
Female <- filter(HELPrct, female == 1)
gf_point(cesd ~ mcs, data = Female, shape = 1) %>%
  gf_smooth(se = FALSE, size = 2)
@
\end{center}
\DiggingDeeper{The \emph{Start Modeling with R} companion book will be helpful if you are unfamiliar with the
modeling language.  The \emph{Start Teaching with R} also provides useful guidance in getting started.}

It's straightforward to plot something besides a character in a scatterplot.  
In this example, the \dataframe{USArrests} can be used to plot the association
between murder and assault rates, with the state name displayed.  This
requires a panel function to be written.   
\Rindex{function()}%
\Rindex{panel.labels()}%
\Rindex{panel.text()}%
\Rindex{rownames()}%
\Rindex{gf\_text()}%
\Rindex{label option}%
<<tidy=FALSE>>=
panel.labels <- function(x, y, labels = 'x',...) { 
  panel.text(x, y, labels, cex = 0.4, ...)
}
gf_text(Murder ~ Assault, panel = panel.labels, 
  label = rownames(USArrests), data = USArrests, 
  size = 2)
@


\vspace*{-1cm}

\section{Correlation}


Correlations can be calculated for a pair of variables, or for a matrix of variables.
\myindex{correlation}%
\Rindex{cor()}%
<<>>=
cor(cesd ~ mcs, data = Female)
smallHELP <- select(Female, cesd, mcs, pcs)
cor(smallHELP)
@
\myindex{Pearson correlation}%
\myindex{Spearman correlation}%

By default, Pearson correlations are provided. Other variants (e.g., Spearman) can be specified using the
\option{method} option.
<<>>=
cor(cesd ~ mcs, method = "spearman", data = Female)
@

\section{Pairs plots}
\myindex{pairs plot}%
\myindex{scatterplot matrix}%

A pairs plot (scatterplot matrix) can be calculated for each pair of a set of variables.
\FoodForThought{The \pkg{GGally} package has support for more elaborate pairs plots.}
\Rindex{ggpairs()}%
<<fig.height=3>>=
library(GGally)
ggpairs(smallHELP)
@

\section{Simple linear regression}

\InstructorNote{We tend to introduce linear regression
early in our courses, as a purely descriptive technique.}
\myindex{linear regression}%
\myindex{regression}%

Linear regression models are described in detail in \emph{Start Modeling with R}.
These use the same formula interface introduced previously for numerical and graphical
summaries
to specify the outcome 
and predictors.  Here we consider fitting the model \model{\variable{cesd}}{\variable{mcs}}.


\Rindex{lm()}%
\Rindex{coef()}%
<<>>=
cesdmodel <- lm(cesd ~ mcs, data = Female)
coef(cesdmodel)
@
\InstructorNote{It's important to pick good names for modeling
objects.  Here the output of \function{lm} is saved as \code{cesdmodel},
which denotes that it is a regression model of depressive symptom
scores.}

To simplify the output, we turn off the option to display significance stars.
\myindex{significance stars}%
\Rindex{msummary()}%
\Rindex{confint()}%
\Rindex{rsquared()}%
\Rindex{coef()}%
<<>>=
options(show.signif.stars = FALSE)
coef(cesdmodel)
msummary(cesdmodel)
coef(summary(cesdmodel))
confint(cesdmodel)
rsquared(cesdmodel)
@


\Rindex{class()}%
<<lmclass>>=
class(cesdmodel)
@
The return value from \function{lm()} is a linear model object.
A number of functions can operate on these objects, as
seen previously with \function{coef()}.  
The function \function{residuals()} returns a
vector of the residuals.
\Rindex{residuals()}%
\FoodForThought{The function \function{residuals()} can be abbreviated 
\function{resid()}.  Another useful function is \function{fitted()}, which 
returns a vector of predicted values.}


\Rindex{density option}%
\begin{center}
<<lmhist>>=
gf_histogram(~ residuals(cesdmodel), density=TRUE)
@
\end{center}
\Rindex{gf\_qq()}%
\begin{center}
<<HELPrct-resid-qq>>=
gf_qq(~ resid(cesdmodel))
@
\end{center}
\Rindex{alpha option}%
\Rindex{gf\_hline()}%
\begin{center}
<<HELPrct-resid-plot, message=FALSE>>=
gf_point(resid(cesdmodel) ~ fitted(cesdmodel), 
         alpha = 0.5, cex = 0.3, pch = 20) %>%
  gf_smooth(se = FALSE) %>%
  gf_hline(yintercept = 0)
@
\end{center}

The \function{mplot()} function can facilitate creating a variety of useful plots, including the same residuals vs. fitted scatterplots, by specifying the \option{which = 1} option.
\Rindex{mplot()}%
\Rindex{which option}%
<<mplotc1, message=FALSE>>=
mplot(cesdmodel, which = 1)
@

It can also generate a normal quantile-quantile plot (\option{which = 2}),
<<mplotc2, results='hide'>>=
mplot(cesdmodel, which = 2)
@

\myindex{scale versus location}%
scale vs.\,location,
<<mplotc3, results='hide', message=FALSE>>=
mplot(cesdmodel, which = 3)
@

\myindex{Cook's distance}%
Cook's distance by observation number,
<<mplotc4, results='hide'>>=
mplot(cesdmodel, which = 4)
@

\myindex{leverage}%
residuals vs.\,leverage,
<<mplotc5,results='hide', message=FALSE>>=
mplot(cesdmodel, which = 5)
@

and Cook's distance vs. leverage.
<<mplotc6,results='hide',message=FALSE>>=
mplot(cesdmodel, which = 6)
@

\myindex{prediction intervals}%
\Rindex{gf\_lm()}%
\Rindex{interval option}%
Prediction intervals can be added to a plot using the \option{interval} option in \function{gf\_lm()}.
\begin{center}
<<HELPxyplot1>>=
gf_point(cesd ~ mcs, data = HELPrct) %>%
  gf_lm(interval = "confidence", fill = "red") %>%
  gf_lm(interval = "prediction", fill = "navy")
@
\end{center}

\begin{problem}
Using the \dataframe{HELPrct} dataset, fit a simple linear regression model 
predicting the number of drinks per day as a function of the mental
component score.  
This model can be specified using the formula:
\model{\variable{i1}}{\variable{mcs}}.  
Assess the distribution of the residuals for this model.
\end{problem}

